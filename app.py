# app.py â€” Streamlit GUI for LangChain chatbot
# -------------------------------------------
# Prereqs:
#   pip install streamlit langchain langchain-openai python-dotenv

from dotenv import load_dotenv
load_dotenv()                 # <â”€ pulls OPENAI_API_KEY from .env

import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# â”€â”€ 0 Â· Page basics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Chitty Chatty Bot", page_icon="ðŸ’¬")  # title + favicon
st.title("ðŸ’¬ Chitty Chatty Bot")                                    # big header

# â”€â”€ 1 Â· Sidebar controls (model, temperature, system prompt) â”€â”€
with st.sidebar:
    st.header("âš™ï¸ Settings")

    model_name = st.selectbox(
        "Model",
        ("gpt-4o-mini", "gpt-4.1-mini", "gpt-4o", "o3-mini"),          # add more as you like
        index=0
    )

    temperature = st.slider(
        "Creativity",
        min_value=0.0,
        max_value=2.0,
        value=1.0,
        step=0.1,
        help="Fuck you, you want some of this? Come and get it."
    )

    system_prompt = st.text_area(
        "System prompt",
        "You are a helpful assistant.",
        height=80
    )

# â”€â”€ 2 Â· LangChain setup (uses sidebar values) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
llm = ChatOpenAI(
    model=model_name,
    temperature=temperature,
    streaming=True
)

prompt_tmpl = ChatPromptTemplate.from_messages(
    [system_prompt, MessagesPlaceholder("history"), ("human", "{user_input}")]
)

# â”€â”€ 3 Â· Session-state chat history â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "history" not in st.session_state:
    st.session_state.history = []        # list of {"role","content"}

# â”€â”€ 4 Â· Replay past turns so they show in the UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for msg in st.session_state.history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# â”€â”€ 5 Â· Handle a new user message â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if user_input := st.chat_input("Ask me anythingâ€¦"):
    st.chat_message("user").markdown(user_input)   # echo user bubble

    # Build & stream the assistantâ€™s reply
    chain = prompt_tmpl | llm
    partial_reply = ""
    with st.chat_message("assistant"):
        stream_area = st.empty()
        for chunk in chain.stream(
            {"user_input": user_input, "history": st.session_state.history}
        ):
            partial_reply += chunk.content or ""
            stream_area.markdown(partial_reply + "â–Œ")   # live cursor
        stream_area.markdown(partial_reply)             # final text

    # Save turn to history so it persists on the next rerun
    st.session_state.history.extend([
        {"role": "user", "content": user_input},
        {"role": "assistant", "content": partial_reply}
    ])